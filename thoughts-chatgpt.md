# Thoughts about ChatGPT, Bard, etc.

## Preamble

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I&#39;ll be headlining a webinar organized by <a href="https://twitter.com/WatSPEEDUW?ref_src=twsrc%5Etfw">@WatSPEEDUW</a> next week on chatGPT, Bard, and its ilk. There&#39;s still time to register! <a href="https://t.co/cUV9qg5QVv">https://t.co/cUV9qg5QVv</a></p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623321120274358275?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">As part of preparing for this event, I&#39;ve gathered some opinions and predictions that I&#39;m willing to express &quot;on the record&quot;. I&#39;ll be sharing my thoughts in subsequent tweets. Let&#39;s see how they age.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623321312742588418?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

## On Prompt Engineering

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">My (contrarian?) take: prompt engineering is programming in natural language. We&#39;ve tried this before, with attempts dating back decades. Recent advances do not change the fact that natural languages are ambiguous, imprecise, under-specified, highly contextual, etc.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623337409248124930?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">What&#39;s going to happen is that prompts will become increasingly stylized, with atoms (tokens) acquiring precise semantics, a rigid but semantically precise means of combination, and a similarly constrained means of abstraction. In other words...</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623337656972181504?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Prompts will become yet another programming language. This is inevitable for anything other than &quot;casual&quot; use.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623337777247952903?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Yes, the prompt programming language will likely be closer to natural language, easier to learn, etc. but it will remain a technical skill that&#39;s non-trivial to learn.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623337892801118210?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">An analogy would be legalese, which *is* natural language, but has acquired many rigid structures that have precise meanings and are often incomprehensible to non-experts (and you go to law school to become proficient).</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623338095037874177?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">This perspective does not preclude the Copilot-like scenario where the programmer interactively builds applications with a LLM, starting from a legalese-like prompt programming language that generates code, which the human then refines. That&#39;s the future I envision.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623338369949306881?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">And in fact, Knuth articulated this vision nearly four decades ago... it&#39;s called Literate Programming <a href="https://t.co/eZ3yRB4U1J">https://t.co/eZ3yRB4U1J</a> and technology has sufficiently caught up that we may finally be able to realize it.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623338536236638212?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

## On Hallucinations and Toxic Content

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">My (contrarian?) predictions on ChatGPT, Bard, and its ilk: Regarding the two biggest problems today, (1) hallucinations and (2) toxicity, the first will be transient (i.e., solved relatively shortly) and the second will be perpetual (i.e., will never be solved). Rationale:</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623352932656680961?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">(1) the hallucination problem is technical and thus solvable (already many promising directions, e.g., retrieval augmentation, attribution techniques, etc.). Pretty soon we&#39;ll be able to accurately probe model output to trace back exactly where each token came from.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623353233086287876?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">LLMs will soon be able to synthesize content from source material (whether pretrained data or retrieval augmentation) with perfect fidelity. This does not address the problem that untruthful content exists (e.g., misinformation) - but the situation will be no worse than today.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623353810193199108?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">It will always be possible to coax untruthful content out of LLMs (for humans, we call this writing fiction), but in &quot;normal&quot; (non-adversarial) use, hallucinations won&#39;t pose a problem.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623354010202677249?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">(2) the toxicity problem will never be solved in an enlightened liberal society, because it&#39;s not a technical problem, but rather a matter of human nature.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623354162397192194?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The InstructGPT paper asks the poignant question of &quot;who are we aligning to?&quot; The answer is, of course, the annotators. We can make LLMs increasingly aligned with the values that most people hold (e.g., racism is bad, child porn is bad), but it is impossible to do better...</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623354428483928071?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">For the simple reason that *humans* generate content (i.e., express opinions) that other humans find toxic, and we tolerate this as a society (within bounds)... it&#39;s called free speech.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623354631903379464?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">LLMs will be increasingly consonant with shared social norms, and, pretty soon, in &quot;normal&quot; (non-adversarial) use, toxic content won&#39;t pose a problem.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623354770881667072?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">However, there exist plenty of opinions (on any controversial topic) that are within the bounds of socially acceptable discourse, but some may find objectionable. It&#39;ll be impossible to prevent LLMs from generating content that at least some find distasteful.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623355380855148545?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">DAN (Do Anything Now) and other &quot;jailbreaks&quot; are equivalent to recording your racist uncle ranting after a few drinks, but your racist uncle is (most likely) a functioning member of society and observes social norms in most situations. It&#39;ll be like that for LLMs.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623355653304492033?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">One major difference, though: humans are accountable for their words, i.e., &quot;freedom of speech, not freedom from consequences&quot;. But it is impossible for LLMs to be accountable for their output.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623355796506480643?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Instead, we&#39;ll take the organizations (or individuals) behind the LLM to task - exactly as what happens today. For example, a company expresses a distasteful opinion, activists organize boycotts.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623355918191669249?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">tl;dr - the disruption from ChatGPT, Bard, LLMs will be mostly transitory, and we&#39;ll reach a (different) equilibrium relatively soon.</p>&mdash; Jimmy Lin (@lintool) <a href="https://twitter.com/lintool/status/1623356016183083008?ref_src=twsrc%5Etfw">February 8, 2023</a></blockquote>

